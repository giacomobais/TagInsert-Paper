{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"CCG\"\n",
    "prop = \"1\"\n",
    "prop_to_prob ={\"1\": \"100%\", \"0.5\": \"50%\", \"0.1\": \"10%\", \"0.25\": \"25%\"}\n",
    "model_to_compare = \"BERT_Encoder\"\n",
    "lang = \"en\"\n",
    "run = \"Run3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "TI_file = f\"predictions/{task}/predictions_TagInsert_{lang}_{prop}_{run}.csv\"\n",
    "m2c_file = f\"predictions/{task}/predictions_{model_to_compare}_{lang}_{prop}_{run}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# go to parent directory\n",
    "os.chdir(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the files\n",
    "TI_preds = []\n",
    "TI_accs = []\n",
    "M2C_preds = []\n",
    "M2C_accs = []\n",
    "\n",
    "with open(TI_file) as f:\n",
    "    # get number of lines in the file\n",
    "    rows = sum(1 for line in f)\n",
    "with open(TI_file) as f:\n",
    "    \n",
    "    for i, line in enumerate(f):\n",
    "        sentence = []\n",
    "        preds = line.strip().split(\", \")\n",
    "        # remove the last comma\n",
    "        # preds[-1] = preds[-1][:-1]\n",
    "        for j, pred in enumerate(preds):\n",
    "            if j == len(preds) - 1 and not pred.startswith(\"Sentence\"):\n",
    "                # remove the last comma\n",
    "                pred = pred[:-1]\n",
    "            if pred.startswith(\"Sentence\"):\n",
    "                TI_accs.append(pred.split(\": \")[1])\n",
    "            elif i != rows - 1:\n",
    "                word, gold, prediction, order = pred.split(\"|\")\n",
    "                sentence.append((word, gold, prediction, order))\n",
    "        if len(sentence) != 0:\n",
    "            TI_preds.append(sentence)\n",
    "\n",
    "with open(m2c_file) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        sentence = []\n",
    "        preds = line.strip().split(\", \")\n",
    "        # remove the last comma\n",
    "        # preds[-1] = preds[-1][:-1]\n",
    "        for j, pred in enumerate(preds):\n",
    "            if j == len(preds) - 1 and not pred.startswith(\"Sentence\") and model_to_compare != \"BERT_Encoder\":\n",
    "                # remove the last comma\n",
    "                pred = pred[:-1]\n",
    "            if pred.startswith(\"Sentence\"):\n",
    "                M2C_accs.append(pred.split(\": \")[1])\n",
    "            elif i != rows - 1:\n",
    "                word, gold, prediction = pred.split(\"|\")\n",
    "                sentence.append((word, gold, prediction))\n",
    "        if len(sentence) != 0:\n",
    "            M2C_preds.append(sentence)\n",
    "\n",
    "TI_accs = [float(acc) for acc in TI_accs]\n",
    "M2C_accs = [float(acc) for acc in M2C_accs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43046 43538 45727 0.9413694316268287 0.952128939138802\n"
     ]
    }
   ],
   "source": [
    "correct_ti = 0\n",
    "correct_m2c = 0\n",
    "total = 0\n",
    "for ti_preds, m2c_preds, ti_accs, m2c_accs in zip(TI_preds, M2C_preds, TI_accs, M2C_accs):\n",
    "    sentence_len = len(ti_preds)\n",
    "    total += sentence_len\n",
    "    for i, (ti, m2c) in enumerate(zip(ti_preds, m2c_preds)):\n",
    "        ti_word, gold, ti_pred, ti_order = ti\n",
    "        m2c_word, _, m2c_pred = m2c\n",
    "        if ti_pred == gold:\n",
    "            correct_ti += 1\n",
    "        if m2c_pred == gold:\n",
    "            correct_m2c += 1\n",
    "\n",
    "print(correct_ti, correct_m2c, total, correct_ti / total, correct_m2c / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, torch\n",
    "\n",
    "if task == \"PMB\":\n",
    "    tgt_to_idx = json.load(open(f\"data/{task}/{lang}/processed/{task}_to_idx.json\"))\n",
    "    idx_to_tgt = json.load(open(f\"data/{task}/{lang}/processed/idx_to_{task}.json\"))\n",
    "    with open(f\"data/{task}/{lang}/processed/word_to_idx.json\", 'r', encoding='utf-8') as f:\n",
    "        word_to_idx = json.load(f)\n",
    "    with open(f\"data/{task}/{lang}/processed/idx_to_word.json\", 'r', encoding='utf-8') as f:\n",
    "        idx_to_word = json.load(f)\n",
    "    train_path = f\"data/{task}/{lang}/processed/train_data.pth\"\n",
    "    val_path = f\"data/{task}/{lang}/processed/val_data.pth\"\n",
    "    test_path = f\"data/{task}/{lang}/processed/test_data.pth\"\n",
    "else:\n",
    "    tgt_to_idx = json.load(open(f\"data/{task}/processed/{prop_to_prob[prop]}/{task}_to_idx.json\"))\n",
    "    idx_to_tgt = json.load(open(f\"data/{task}/processed/{prop_to_prob[prop]}/idx_to_{task}.json\"))\n",
    "    word_to_idx = json.load(open(f\"data/{task}/processed/{prop_to_prob[prop]}/word_to_idx.json\"))\n",
    "    idx_to_word = json.load(open(f\"data/{task}/processed/{prop_to_prob[prop]}/idx_to_word.json\"))\n",
    "    train_path = f\"data/{task}/processed/{prop_to_prob[prop]}/train_data.pth\"\n",
    "    val_path = f\"data/{task}/processed/{prop_to_prob[prop]}/val_data.pth\"\n",
    "    test_path = f\"data/{task}/processed/{prop_to_prob[prop]}/test_data.pth\"\n",
    "train_data = torch.load(train_path)\n",
    "val_data = torch.load(val_path)\n",
    "test_data = torch.load(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(',', 52749),\n",
       "  ('the', 44759),\n",
       "  ('.', 42360),\n",
       "  ('of', 24837),\n",
       "  ('to', 24046),\n",
       "  ('a', 20848),\n",
       "  ('and', 17264),\n",
       "  ('in', 16437),\n",
       "  (\"'s\", 10145),\n",
       "  ('that', 8650)],\n",
       " [('N', 182074),\n",
       "  ('N/N', 151657),\n",
       "  ('NP/N', 83736),\n",
       "  ('PP/NP', 56438),\n",
       "  (',', 52749),\n",
       "  ('.', 42849),\n",
       "  ('N/PP', 37774),\n",
       "  ('conj', 21975),\n",
       "  ('(N/N)/(N/N)', 20117),\n",
       "  ('NP', 19969)])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_freqs = Counter()\n",
    "tag_freqs = Counter()\n",
    "\n",
    "for sentence in train_data['words']:\n",
    "    for word in sentence:\n",
    "        if word != word_to_idx['<PAD>']:\n",
    "            word_string = idx_to_word[str(word)]\n",
    "            word_freqs[word_string] += 1\n",
    "\n",
    "for sentence in train_data['tags']:\n",
    "    for tag in sentence:\n",
    "        if tag != tgt_to_idx['<PAD>'] and tag != tgt_to_idx['<START>']:\n",
    "            tag_string = idx_to_tgt[str(tag)]\n",
    "            tag_freqs[tag_string] += 1\n",
    "\n",
    "word_freqs.most_common(10), tag_freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unseen words: 1618\n",
      "TI accuracy on unseen words: 0.9295426452410384\n",
      "BERT_Encoder accuracy on unseen words: 0.946229913473424\n",
      "Average normalized order of unseen words: 0.6118882563579716\n",
      "Average normalized index of unseen words: 0.45067907892956965\n"
     ]
    }
   ],
   "source": [
    "normalized_orders = []\n",
    "normalized_indeces = []\n",
    "ti_unseen_words_accs = []\n",
    "m2c_unseen_words_accs = []\n",
    "for ti_preds, m2c_preds, ti_accs, m2c_accs in zip(TI_preds, M2C_preds, TI_accs, M2C_accs):\n",
    "    # calculate accuracy of the two models on unseen words\n",
    "    for i, (ti, m2c) in enumerate(zip(ti_preds, m2c_preds)):\n",
    "        ti_word, gold, ti_pred, ti_order = ti\n",
    "        m2c_word, _, m2c_pred = m2c\n",
    "        if ti_word not in word_freqs:\n",
    "            ti_unseen_words_accs.append(ti_pred == gold)\n",
    "            normalized_order = float(ti_order) / len(ti_preds)\n",
    "            normalized_orders.append(normalized_order)\n",
    "            m2c_unseen_words_accs.append(m2c_pred == gold)\n",
    "            normalized_index = float(i) / len(ti_preds)\n",
    "            normalized_indeces.append(normalized_index)\n",
    "\n",
    "print(f\"Number of unseen words: {len(ti_unseen_words_accs)}\")\n",
    "print(f\"TI accuracy on unseen words: {sum(ti_unseen_words_accs) / len(ti_unseen_words_accs)}\")\n",
    "print(f\"{model_to_compare} accuracy on unseen words: {sum(m2c_unseen_words_accs) / len(m2c_unseen_words_accs)}\")\n",
    "print(f\"Average normalized order of unseen words: {sum(normalized_orders) / len(normalized_orders)}\")\n",
    "print(f\"Average normalized index of unseen words: {sum(normalized_indeces) / len(normalized_indeces)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 321, 1089)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequent_tags = [tag for tag, freq in tag_freqs.items() if freq >= 100]\n",
    "common_tags = [tag for tag, freq in tag_freqs.items() if freq >= 10 and freq < 100]\n",
    "rare_tags = [tag for tag, freq in tag_freqs.items() if freq < 10]\n",
    "\n",
    "len(frequent_tags), len(common_tags), len(rare_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frequent tags: 45191\n",
      "TI accuracy on frequent tags: 0.9474674160784227\n",
      "BERT_Encoder accuracy on frequent tags: 0.9573366378261158\n",
      "Average normalized order of frequent tags: 0.516362990237016\n",
      "Average normalized index of frequent tags: 0.48004863567831235\n",
      "Number of common tags: 428\n",
      "TI accuracy on common tags: 0.5093457943925234\n",
      "BERT_Encoder accuracy on common tags: 0.6401869158878505\n",
      "Average normalized order of common tags: 0.9040693338358383\n",
      "Average normalized index of common tags: 0.40202082762790475\n",
      "Number of rare tags: 92\n",
      "TI accuracy on rare tags: 0.010869565217391304\n",
      "BERT_Encoder accuracy on rare tags: 0.07608695652173914\n",
      "Average normalized order of rare tags: 0.8981887149276789\n",
      "Average normalized index of rare tags: 0.3787890212260492\n",
      "Number of OOV tags: 16\n",
      "TI accuracy on OOV tags: 0.0\n",
      "BERT_Encoder accuracy on OOV tags: 0.0\n",
      "Average normalized order of OOV tags: 0.8728169714950174\n",
      "Average normalized index of OOV tags: 0.48178755524046696\n"
     ]
    }
   ],
   "source": [
    "normalized_freq_orders, normalized_freq_indeces = [], []\n",
    "normalized_common_orders, normalized_common_indeces = [], []\n",
    "normalized_rare_orders, normalized_rare_indeces = [], []\n",
    "normalized_oov_orders, normalized_oov_indeces = [], []\n",
    "ti_freq_tags_accs, m2c_freq_tags_accs = [], []\n",
    "ti_common_tags_accs, m2c_common_tags_accs = [], []\n",
    "ti_rare_tags_accs, m2c_rare_tags_accs = [], []\n",
    "ti_oov_tags_accs, m2c_oov_tags_accs = [], []\n",
    "for ti_preds, m2c_preds, ti_accs, m2c_accs in zip(TI_preds, M2C_preds, TI_accs, M2C_accs):\n",
    "    for i, (ti, m2c) in enumerate(zip(ti_preds, m2c_preds)):\n",
    "        ti_word, gold, ti_pred, ti_order = ti\n",
    "        m2c_word, _, m2c_pred = m2c\n",
    "        if gold not in frequent_tags and gold not in common_tags and gold not in rare_tags:\n",
    "            ti_oov_tags_accs.append(ti_pred == gold)\n",
    "            normalized_order = float(ti_order) / len(ti_preds)\n",
    "            normalized_oov_orders.append(normalized_order)\n",
    "            m2c_oov_tags_accs.append(m2c_pred == gold)\n",
    "            normalized_index = float(i) / len(ti_preds)\n",
    "            normalized_oov_indeces.append(normalized_index)\n",
    "        elif gold in frequent_tags:\n",
    "            ti_freq_tags_accs.append(ti_pred == gold)\n",
    "            normalized_order = float(ti_order) / len(ti_preds)\n",
    "            normalized_freq_orders.append(normalized_order)\n",
    "            m2c_freq_tags_accs.append(m2c_pred == gold)\n",
    "            normalized_index = float(i) / len(ti_preds)\n",
    "            normalized_freq_indeces.append(normalized_index)\n",
    "        elif gold in common_tags:\n",
    "            ti_common_tags_accs.append(ti_pred == gold)\n",
    "            normalized_order = float(ti_order) / len(ti_preds)\n",
    "            normalized_common_orders.append(normalized_order)\n",
    "            m2c_common_tags_accs.append(m2c_pred == gold)\n",
    "            normalized_index = float(i) / len(ti_preds)\n",
    "            normalized_common_indeces.append(normalized_index)\n",
    "        elif gold in rare_tags:\n",
    "            ti_rare_tags_accs.append(ti_pred == gold)\n",
    "            normalized_order = float(ti_order) / len(ti_preds)\n",
    "            normalized_rare_orders.append(normalized_order)\n",
    "            m2c_rare_tags_accs.append(m2c_pred == gold)\n",
    "            normalized_index = float(i) / len(ti_preds)\n",
    "            normalized_rare_indeces.append(normalized_index)\n",
    "\n",
    "print(f\"Number of frequent tags: {len(ti_freq_tags_accs)}\")\n",
    "print(f\"TI accuracy on frequent tags: {sum(ti_freq_tags_accs) / len(ti_freq_tags_accs)}\")\n",
    "print(f\"{model_to_compare} accuracy on frequent tags: {sum(m2c_freq_tags_accs) / len(m2c_freq_tags_accs)}\")\n",
    "print(f\"Average normalized order of frequent tags: {sum(normalized_freq_orders) / len(normalized_freq_orders)}\")\n",
    "print(f\"Average normalized index of frequent tags: {sum(normalized_freq_indeces) / len(normalized_freq_indeces)}\")\n",
    "print(f\"Number of common tags: {len(ti_common_tags_accs)}\")\n",
    "print(f\"TI accuracy on common tags: {sum(ti_common_tags_accs) / len(ti_common_tags_accs)}\")\n",
    "print(f\"{model_to_compare} accuracy on common tags: {sum(m2c_common_tags_accs) / len(m2c_common_tags_accs)}\")\n",
    "print(f\"Average normalized order of common tags: {sum(normalized_common_orders) / len(normalized_common_orders)}\")\n",
    "print(f\"Average normalized index of common tags: {sum(normalized_common_indeces) / len(normalized_common_indeces)}\")\n",
    "print(f\"Number of rare tags: {len(ti_rare_tags_accs)}\")\n",
    "if len(ti_rare_tags_accs) > 0:\n",
    "    print(f\"TI accuracy on rare tags: {sum(ti_rare_tags_accs) / len(ti_rare_tags_accs)}\")\n",
    "    print(f\"{model_to_compare} accuracy on rare tags: {sum(m2c_rare_tags_accs) / len(m2c_rare_tags_accs)}\")\n",
    "    print(f\"Average normalized order of rare tags: {sum(normalized_rare_orders) / len(normalized_rare_orders)}\")\n",
    "    print(f\"Average normalized index of rare tags: {sum(normalized_rare_indeces) / len(normalized_rare_indeces)}\")\n",
    "if len(ti_oov_tags_accs) > 0:\n",
    "    print(f\"Number of OOV tags: {len(ti_oov_tags_accs)}\")\n",
    "    print(f\"TI accuracy on OOV tags: {sum(ti_oov_tags_accs) / len(ti_oov_tags_accs)}\")\n",
    "    print(f\"{model_to_compare} accuracy on OOV tags: {sum(m2c_oov_tags_accs) / len(m2c_oov_tags_accs)}\")\n",
    "    print(f\"Average normalized order of OOV tags: {sum(normalized_oov_orders) / len(normalized_oov_orders)}\")\n",
    "    print(f\"Average normalized index of OOV tags: {sum(normalized_oov_indeces) / len(normalized_oov_indeces)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tags where TI is right and BERT_Encoder is wrong: 27\n",
      "Number of unique tags where TI is right and BERT_Encoder is wrong: 24\n",
      "Average normalized order of words where TI is right and BERT_Encoder is wrong: 0.912066431510876\n",
      "Average normalized index of words where TI is right and BERT_Encoder is wrong: 0.3610082304526749\n",
      "Most common TI preds where TI is right and BERT_Encoder is wrong: [('(NP\\\\NP)/NP', 3), ('(S[ng]\\\\NP)/PP', 2), ('(S[dcl]\\\\PP)/NP', 1), ('(S[adj]\\\\NP)/(S[adj]\\\\NP)', 1), ('S[q]\\\\S[dcl]', 1), ('(S[dcl]\\\\NP)/(S[b]\\\\NP)', 1), ('(S[b]\\\\NP)/(S[adj]\\\\NP)', 1), ('(S[pt]\\\\NP)\\\\NP', 1), ('(S[b]\\\\NP)/NP', 1), ('(S[dcl]\\\\NP)/PP', 1)]\n",
      "Most common BERT_Encoder preds where TI is right and BERT_Encoder is wrong: [('(S[dcl]\\\\NP)/NP', 5), ('(S[dcl]\\\\NP)/(S[dcl]\\\\NP)', 3), ('S[pt]\\\\NP', 2), ('((S[dcl]\\\\NP)\\\\(S[dcl]\\\\NP))/NP', 2), ('S[ng]\\\\NP', 2), ('(S[dcl]\\\\NP)/(S[ng]\\\\NP)', 2), ('N\\\\N', 2), ('PP/NP', 2), ('S[adj]\\\\NP', 1), ('(S[dcl]\\\\NP)/(S[adj]\\\\NP)', 1)]\n"
     ]
    }
   ],
   "source": [
    "normalized_orders = []\n",
    "normalized_indeces = []\n",
    "right_for_ti = []\n",
    "wrong_for_m2c = []\n",
    "sentences_right_for_ti = []\n",
    "for ti_preds, m2c_preds, ti_accs, m2c_accs in zip(TI_preds, M2C_preds, TI_accs, M2C_accs):\n",
    "    sentence_len = len(ti_preds)\n",
    "    for i, (ti, m2c) in enumerate(zip(ti_preds, m2c_preds)):\n",
    "        ti_word, gold, ti_pred, ti_order = ti\n",
    "        m2c_word, _, m2c_pred = m2c\n",
    "        if ti_pred == gold and m2c_pred != gold:\n",
    "            if (ti_preds, m2c_preds) not in sentences_right_for_ti:\n",
    "                sentences_right_for_ti.append((ti_preds, m2c_preds))\n",
    "            right_for_ti.append(ti_pred)\n",
    "            wrong_for_m2c.append(m2c_pred)\n",
    "            normalized_index = float(i) / sentence_len\n",
    "            normalized_indeces.append(normalized_index)\n",
    "            normalized_order = float(ti_order) / sentence_len\n",
    "            normalized_orders.append(normalized_order)\n",
    "\n",
    "right_counter = Counter(right_for_ti)\n",
    "wrong_counter = Counter(wrong_for_m2c)\n",
    "\n",
    "print(f\"Number of tags where TI is right and {model_to_compare} is wrong: {len(right_for_ti)}\")\n",
    "print(f\"Number of unique tags where TI is right and {model_to_compare} is wrong: {len(right_counter)}\")\n",
    "print(f\"Average normalized order of words where TI is right and {model_to_compare} is wrong: {sum(normalized_orders) / len(normalized_orders)}\")\n",
    "print(f\"Average normalized index of words where TI is right and {model_to_compare} is wrong: {sum(normalized_indeces) / len(normalized_indeces)}\")\n",
    "print(f\"Most common TI preds where TI is right and {model_to_compare} is wrong: {right_counter.most_common(10)}\")\n",
    "print(f\"Most common {model_to_compare} preds where TI is right and {model_to_compare} is wrong: {wrong_counter.most_common(10)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of commas and periods where TI is wrong: 0\n",
      "Number of commas and number of periods where TI is wrong: Counter()\n",
      "Number of commas and periods where BERT_Encoder is wrong: 0\n",
      "Number of commas and number of periods where BERT_Encoder is wrong: Counter()\n"
     ]
    }
   ],
   "source": [
    "# count how many times both model get wrong a comma or a period\n",
    "normalized_orders = []\n",
    "normalized_indeces = []\n",
    "ti_wrong_comma_period = []\n",
    "m2c_wrong_comma_period = []\n",
    "for ti_preds, m2c_preds, ti_accs, m2c_accs in zip(TI_preds, M2C_preds, TI_accs, M2C_accs):\n",
    "    sentence_len = len(ti_preds)\n",
    "    for i, (ti, m2c) in enumerate(zip(ti_preds, m2c_preds)):\n",
    "        ti_word, gold, ti_pred, ti_order = ti\n",
    "        m2c_word, _, m2c_pred = m2c\n",
    "        if gold in [',', '.']:\n",
    "            if ti_pred != gold:\n",
    "                ti_wrong_comma_period.append(gold)\n",
    "                normalized_order = float(ti_order) / sentence_len\n",
    "                normalized_orders.append(normalized_order)\n",
    "            if m2c_pred != gold:\n",
    "                m2c_wrong_comma_period.append(gold)\n",
    "                normalized_index = float(i) / sentence_len\n",
    "                normalized_indeces.append(normalized_index)\n",
    "\n",
    "ti_wrong_comma_period_counter = Counter(ti_wrong_comma_period)\n",
    "m2c_wrong_comma_period_counter = Counter(m2c_wrong_comma_period)\n",
    "\n",
    "print(f\"Number of commas and periods where TI is wrong: {len(ti_wrong_comma_period)}\")\n",
    "print(f\"Number of commas and number of periods where TI is wrong: {ti_wrong_comma_period_counter}\")\n",
    "if len(normalized_orders) > 0:\n",
    "    print(f\"Average normalized order of commas and periods where TI is wrong: {sum(normalized_orders) / len(normalized_orders)}\")\n",
    "print(f\"Number of commas and periods where {model_to_compare} is wrong: {len(m2c_wrong_comma_period)}\")\n",
    "print(f\"Number of commas and number of periods where {model_to_compare} is wrong: {m2c_wrong_comma_period_counter}\")\n",
    "if len(normalized_indeces) > 0: \n",
    "    print(f\"Average normalized index of commas and periods where {model_to_compare} is wrong: {sum(normalized_indeces) / len(normalized_indeces)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences_right_for_ti)\n",
    "with open(f\"predictions/TI_right_{model_to_compare}_wrong_{task}_{prop}.txt\", \"w\") as f:\n",
    "    for i, (ti_preds, m2c_preds) in enumerate(sentences_right_for_ti):\n",
    "        f.write(f\"{i}): \")\n",
    "        for ti, m2c in zip(ti_preds, m2c_preds):\n",
    "            ti_word, gold, ti_pred, ti_order = ti\n",
    "            m2c_word, _, m2c_pred = m2c\n",
    "            if ti_pred == gold and m2c_pred != gold:\n",
    "                f.write(f\"{ti_word.upper()}|{gold.upper()}|{ti_pred.upper()}|{ti_order.upper()}|{m2c_pred.upper()} \")\n",
    "            else:\n",
    "                f.write(f\"{ti_word}|{gold}|{ti_order}| \")\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
