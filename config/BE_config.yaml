model_name: "BERT_Encoder"
bert_model: "bert-base-cased"
device: "cuda"
lr: 0.00002
betas: [0.9, 0.98]
eps: 0.000000001
warmup: 400
weight_decay: 0.01
batch_size: 24
epochs: 5
block_size: 102
bert_block_size: 200
data_proportion: 0.1
embedding_strategy: "prefix"